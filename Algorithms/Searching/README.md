# Searching Algorithms

Aлгоритмите за търсене са алгоритми за намиране на елемент със специфични свойства от колекция от елементи.

Име | метод 
------- | ------- 
**Linear Search** – *последователно търсене* |  обхожда елемент по елемент
*Последователно търсене в сортиран списък* |  обхожда елемент по елемент, до достигане на такъв с по-голям ключ
*Последователно търсене с преподреждане* |  обхожда елемент по елемент и актуализира позицията на всеки търсен елемент 
**Quadratic Search** *Търсене със стъпка/Kвадратично търсене*  |  обхожда сектор по сектор в сортиран списък
**Binary Search** *Двоично търсене* | игнорира многократно безперспективната област на търсене в масива
**Fibonacci Search** *Разновидност на двоичното търсене без делене на масива* | различен избор на елемент за сравняване след разделянето на две части

### 1. Последователно търсене
Най-елементарният и очевиден алгоритъм за търсене е последователното търсене. Нека предположим, че елементите на множеството се съдържат в едномерен масив. Търсенето се извършва посредством последователно преглеждане на елементите на масива до откриване на търсеният елемент или до преглеждане на всички елементи. Последното означава, че елемент с такъв ключ не съществува. При постъпване на нов елемент ще го вмъкваме в края на масива *seq_search()*. Следва една възможна реализация на основните функции, основаваща се на последователното търсене:

```cpp
#include <iostream>
#include <ctime>

using namespace std;

const int MAX = 10;

#define DataType int

struct Elem {
    int key;
    DataType data;
    /*...*/
} m[MAX + 1]; // Array of elements

int n;

void seq_init() { // init
    n = 0;
}

int seq_search(int key) { // search
    int x;
    m[0].key = key;
    for (x = n + 1; key != m[--x].key;);
    return x;
}

void seq_insert(int key, DataType data) // add
{
    m[++n].key = key;
    m[n].data = data;
}

void seq_print() { // display the array
    for (int i = 1; i <= n; ++i) {
        cout << m[i].key << ' ' << m[i].data << endl;
    }
}

void perform_search_test() {
    int ind;
    int elem_2_search;

    for (elem_2_search = 0; elem_2_search < 2 * MAX; elem_2_search++) {
        cout << "We search an element with key " << elem_2_search << endl;
        if (0 == (ind = seq_search(elem_2_search))) {
            cout << "Element with such key does not exist!" << endl << endl;
        } else {
            cout << "Item found! Info part: " << m[ind].data << endl << endl;
        }
    }
}

int main() {
    srand(time(nullptr));
    int index;
    seq_init();

    for (index = 0; index < MAX; ++index) {
        seq_insert(rand() % (MAX * 2), index);
    }

    cout << "the list contains the following items:\n";
    seq_print();

    cout << "Testing:"<< endl;
    perform_search_test();

    return 0;
}
```
По-горе сме приели, че същинската информационна част на елементите на масива съдържа единствено поле *data*. Както се забелязва, търсенето се извършва последователно по посока на намаляване на индексите. Забележете, че нулевия елемент на масива не съдържа елемент на множеството, а служебна информация. Той е използван като *елемент-ограничител*, позволяващ опростяване на цикъла: проверява се само едно условие, тъй като сме осигурили намирането на елемент със зададения ключ (в краен случай нулевият). В случай на дублиране на ключове горният алгоритъм очевидно връща последния постъпил елемент с този ключ. 

Каква е сложността на алгоритъма в средния и в най-лошия случай съответно? Ясно е, че най-лошият случай е когато търсеният елемент липсва. Тогава се преглеждат всичките *n + 1* елемента на масива, включително нулевият. В общия случай, когато търсенето е успешно, средният брой на извършените сравнения е (n+1)/2. Същевременно, за намиране на всички елементи с даден ключ е необходимо *цялостно* преглеждане на масива.

#### 1.1. Последователно търсене в сортиран списък:

Последователното търсене, разгледано по-горе, е най-простият и най-неефективният алгоритъм за търсене. Бихме могли да се опитаме да подобрим ефективността му, поддържайки елементите в сортиран вид. Това ще ни се отдаде сравнително лесно, ако използваме свързан списък вместо масив. Всичко което трябва да направим, е да вмъкваме всеки новопостъпил елемент на съответното му място, така че списъкът да остава сортиран. Така преди всяко вмъкване ще се изисква извършване на съответно търсене, за да се открие съответната позиция.

Операцията по вмъкване се усложнява значително. По-горе я извършвахме за константно време, без нито едно сравнение, а сега това ще изисква предварително търсене. Какво все пак постигнахме? Обстоятелството, че елементите са подредени в нарастващ ред, ще ни позволи да прекратяваме по-нанатъшното търсене при достигане на елемент с ключ, по-голям от търсения. Броят на необходимите сравнения в случай на неуспешно търсене намалява до (n+1)/2, в сравнение с n+1 при несортирания случай. На практика успешното и неуспешното търсене се оказват равнопоставени, тъй като тази модификация очевидно не влияе на успешното търсене. В най-лошия случай отново трябва да се прегледат всички елементи, т.е. да се извършат n + 1 сравнения. Оказва се, че в замяна на това, че сме приравнили сложността на вмъкването, която по-рано беше константна, към сложността на търсенето, получаваме само равнопоставеност на успешно и неуспешно търсене. Полученият реултат е изключително поучителен и показва, че преди да се пристъпи към някаква „очевидна“ оптимизация, следва много внимателно да се прецени възможната полза и вреда, които тя ще принесе.

Следва примерна реализация на последователно търсене в сортиран списък, заедно със съответна версия на функции за вмъкване и инициализиране:

```cpp
#include <iostream>
#include <ctime>

using namespace std;

const int MAX = 10;

#define DataType int

struct Elem {
    int key;
    DataType data;
    struct Elem *next;

    /* ... */
} *head;

void list_init() {
    head = (struct Elem *) malloc(sizeof *head);
    head->next = nullptr;
}

void list_insert(int key, DataType data) {
    struct Elem *p, *q, *r;

    q = (struct Elem *) malloc(sizeof *head);
    r = (p = head)->next;

    while (r != nullptr && r->key < key) {
        p = r;
        r = r->next;
    }

    q->key = key;
    q->data = data;
    q->next = r;
    p->next = q;
}

struct Elem *list_search(int key) {
    struct Elem *q;

    for (q = head->next; q != nullptr && q->key < key; q = q->next);

    if (nullptr == q || key != q->key) {
        return nullptr;
    } else {
        return q;
    }
}

void list_display() {
    struct Elem *q;
    for (q = head->next; q != nullptr; q = q->next) {
        cout << q->key << ' ' << q->data << endl;
    }
}

int main() {
    srand(time(nullptr));
    int index;
    list_init();

    for (index = 0; index < MAX; index++) {
        list_insert(rand() % (MAX * 2), index);
    }
    cout << "the list contains the following items:" << endl;
    list_display();

    cout << "Searching:" << endl;
    Elem *el = list_search(10);

    if (el) {
        cout << "Element found: key " << el->key << "; data " << el->data << endl;
    } else {
        cout << "No element with such key found." << endl;
    }

    return 0;
}
```
#### 1.2. Последователно търсене с преподреждане:

В случай, че разполагаме с предварителна информация относно вероятността за достъп до всеки от елементите, бихме могли да ги подредим така, че най-често търсеният да бъде на върха на списъка, следващият – непосредствено след него и т.н. Използването на подобна стратегия се оказва изключително ефективно, особено при силно неравномерно разпределение, при което малък брой елементи се търсят с много голяма вероятност.

В случай, че не разполагаме с такава предварителна информация, бихме могли сами да си я получим с помощта на прости статистически наблюдения: достатъчно е към всеки елемент да прикрепим брояч на достъпа до него. При всяко ново търсене ще актуализираме брояча на търсения елемент. Ясно е, че след актуализацията той евентуално ще може да мине по-напред в списъка. Ето защо следва да се направи сравнение с предходния елемент в списъка, при което евентуално двата да се разменят. Тъй като в списъка може да има многократно дублиране на честотите на достъп, в случай на размяна се налага съответно сравнение и със следващия предходен елемент и т.н. до достигане на точната позиция, съответстваща на новата честота на елемента. Реорганизацията става за време, пропорционално на n, като в най-лошия случай може да се случи последният елемент на списъка да стане първи, разменяйки се последователно с всички преди него [*Уирт-1980*].

Предложената по-горе схема с поддържане на специални броячи, се оказва тромава, изисква допълнителна памет от порядъка на n и би могла да се оптимизира. За пореден път се оказва, че простото е по-добро. Действително, в този случай се оказва изключително ефективно прилагането на по-проста стратегия за реорганизация. Не се поддържат никакви броячи и не се води никаква статистика. Вместо това, при всяко успешно търсене на елемент той се поставя в началото на списъка. Разбира се тази стратегия не ни гарантира оптимално подреждане на елементите съгласно честотата им на достъп, но пък е лесна за поддържане и достатъчно ефективна. Действително, за разлика от варианта с броячите, тук реорганизацията става за константно време. От друга страна, колкото по-често е осъществяван достъп до даден елемент, с толкова по-голяма вероятност той ще се намира сред първите елементи на списъка. При това така по-добре се отчитат локалните особености: ако някой глобално погледнато рядко търсен елемент в даден момент се търси често, тази стратегия ще ни позвили да се възползваме от това.

```cpp
#include <iostream>
#include <ctime>

using namespace std;

const int MAX = 10;

#define DataType int

struct Elem {
    int key;
    DataType data;
    struct Elem *next;

    /* ... */
} *head;

void list_init() {
    head = (struct Elem *) malloc(sizeof *head);
    head->next = nullptr;
}

void list_insert(int key, DataType data) {
    auto *q = (struct Elem *) malloc(sizeof *head);

    q->key = key;
    q->data = data;
    q->next = head;

    head = q;
}

struct Elem *list_search(int key) {
    struct Elem *q, *p = head;

    if (nullptr == head) {
        return nullptr;
    }

    if (head->key == key) return head;

    for (q = head->next; q != nullptr;) {
        if (q->key != key) {
            p = q;
            q = q->next;
        } else {
            p->next = q->next;
            q->next = head;
            return (head = q);
        }
    }

    return nullptr;
}

void list_display() {
    struct Elem *q;
    for (q = head; q->next != nullptr; q = q->next) {
        cout << q->key << ' ' << q->data;
        cout << endl;
    }
}

int main() {
    srand(time(nullptr));
    int ind;
    list_init();

    for (ind = 0; ind < MAX; ++ind) {
        list_insert(rand() % (MAX * 2), ind);
    }
    cout << "the list contains the following items:" << endl;
    list_display();

    cout << "Searching:" << endl;
    Elem *el = list_search(10);
    if (el) {
        cout << "Element found: key " << el->key << "; data " << el->data << endl;
    } else {
        cout << "No element with such key found" << endl;
    }
    list_display();
    return 0;
}
```

### 2. Търсене със стъпка. Квадратично търсене (Qadratic search)

Нека отново разгледаме случая на наредено множество. Разгледаният по-горе метод на търсене в сортиран списък се отличаваше незначително от стандартното последователно търсене и не използваше достатъчно пълноценно наредбата на елементите. Ще се опитаме да поправим тази грешка, като за целта ще възприемем коренно различен подход. Нека изберем някаква стъпка k и последователно извършваме проверката дали ключът на търсения елемент е по-голям от първия елемент, от (k + 1)-ия елемент, от (2k + 1)-ия елемент, от (3k + 1)-ия елемент, ... Т.е. сравняваме го с m[1].key, m[k + 1].key, m[2 * k+1].key, ... . Процесът приключва при достигане на елемент, по-голям или равен на x, или на края на масива.

Да разгледаме по-внимателно горната схема (ще я наричаме *търсене със стъпка*). Нека предположим, че, прилагайки я, сме достигнали до елемент, по-голям от x. Сега може да използваме последователно търсене в интервала, определен от последните две проби. В случай, че сме били излезли извън масива, можем да използваме последователно търсене от предишната проба до края на масива. Очевидно подобен подход би могъл да доведе до силно съкращаване на броя на елементите, които се преглеждат от последователното търсене. Освен това лесно се вижда, че използвания метод е обобщение на линейното търсене. Действително, последното се получава при k = 1.

Съгласно приведеното по-горе описание, предложеният метод винаги започва с m[1].key. Доколко подобно начало е удачно? Не е трудно да се види, че това всъщност е лош избор, при това по същите причини, по които е лош изборът m[n].key: носи минимално количество информация. Оказва се, че е много по удачно да се започне направо с m[k].key. Лесно се вижда, че и в този случай при k = 1 се получава линейно търсене.

Каква е ефективността на описания метод при фиксирано k и кой е най-лошия случай? Ясно е, че линейното търсене има еднаква цена за всички инервали от вида [ m[i * k + 1].key; m[(i + 1) * k].key ], тъй като се извършва върху еднакъв брой елементи. Изключение може да прави единствено последният интервал, който евентуално може да съдържа по малко от k елемента. В най-лошия случай търсеният ключ е в последния интервал, което означава, че ще ни бъде необходимо [n/k] сравнения, за да определим нужния ни интервал, в който да приложим линейното търсене. Към тях следва да прибавим дължината на интервала, която при n, кратно на k, е k - 1. Получаваме, че в най-лошия случай при търсене със стъпка k се извършват не повече от [n/k] + k - 1 сравнения.

Следва примерна реализация на описания алгоритъм:

```cpp
#include <iostream>
#include <ctime>
#include <algorithm>
#include <cmath>

using namespace std;

const int KEY = 7;
const int MAX = 10;

#define DataType int

struct Elem {
    int key;
    DataType data;

    /*...*/
} m[MAX + 1];

int n;

void seq_init() {
    n = 0;
}

bool way_to_sort(Elem i, Elem j) {
    return i.key < j.key;
}

void seq_insert(int key, DataType data) {
    m[++n].key = key;
    m[n].data = data;
    sort(m + 1, m + n + 1, way_to_sort);
}

int seq_search(int l, int r, int key) {
    while (l <= r) {
        if (m[l++].key == key) {
            return l - 1;
        }
    }

    return -1;
}

int jump_search(int key, int step) {
    int ind;
    for (ind = 0; ind < n && m[ind].key < key; ind += step);
    return seq_search(ind + 1 < step ? 0 : ind + 1 - step, n < ind ? n : ind, key);
}

void seq_display() {

    for (int i = 1; i <= n; i++) {
        cout << "position "
             << i
             << " : key "
             << m[i].key
             << " data "
             << m[i].data
             << endl;
    }
}

int main() {
    srand(time(nullptr));
    int ind;
    seq_init();
    for (ind = 0; ind < MAX; ++ind) {
        seq_insert(rand() % (MAX * 2), ind);
    }
    cout << "the list contains the following items:" << endl;
    seq_display();

    cout << "Testing:" << endl;
    int el = jump_search(KEY, sqrt(n));


    (el != -1) ? cout << "Element with key " << KEY << " found at position " << el : cout << "No element with key "
                                                                                          << KEY;
    return 0;
}
```

Възниква важният въпрос: Как, при зададено n да избираме k така, че да осигурим максимална ефективност? Таблица 2.1. показва максималния брой сравнения, извършвани от вмъкването със стъпка при различни стойности на n и k:

n/k|1|2|3|4|5|6|7|8
----|----|----|----|----|----|----|----|----
**1**|1| | | | | | |  
**2**|2|2| | | | | | 
**3**|3|2|3| | | | | 
**4**|4|3|3|4| | | |  
**5**|5|3|3|4|5| | | 
**6**|6|4|4|4|5|6| | 
**7**|7|4|4|4|5|6|7| 
**8**|8|5|4|5|5|6|7|8

**Таблица 2.1.** Максимален брой сравнения при различни стойности на n и k.

Вижда се, че най-добрите стойности на k са близки до n/2, т.е. разположени са в средата на съответния ред на таблицата или непосредствени вляво от нея. За да определим по-прецизно кои стойности на k са най-добри и как зависят от n, следва да определим при каква зависимост между n и k функцията f(k) приема минимална стойност: 

f(k)=[\frac{n}{k}]+k-1.

Не е трудно да се покаже (например с изследване на знака на втората производна), че това е стойността k=\sqrt{n}. Тогава f(k) < 2\sqrt{n}+1. В този случай търсенето се нарича *квадратично* .

И така, постигнахме едно наистина добро подобрение: от n до \sqrt{n}. Бихме ли могли да постигнем повече? Както следва да се очаква, отговорът на този въпрос е положителен. Действително по-горе минимизирахме f(k) предполагайки, че след определяне на интервала ще извършим последователно търсене. И точно тук идва идеята: А какво ще стане, ако в този момент приложим още веднъж търсене с някаква нова стъпка l (1 < l < k) и едва след това последователно търсене? Действително, дължината на интервала след първото търсене със стъпка k е \sqrt{n}, което може да бъде достатъчно голямо число, така че подобно подобрение би било разумно. Сега на първата стъпка ще имаме не повече от k сравнения за определяне на първия интервал, след това не повече от l сравнения – за определяне на втория, и накрая не повече от \frac{n}{k\times{l}} – за последователното търсене. Може да образуваме нова функция, която да минимизираме, като в този случай лесно се получава, че минимумът се достига за k = l = \frac{n}{k\times{l}}">, откъдето n = k^3. В този случай алгоритъмът ще извършва не повече от\sqrt[3]{n} сравнения. За n > 12 се получава, че 3\sqrt[3]{n} < 2\sqrt{n} , т.е. постигнахме подобрение [*Gregory, Rawlins-1997*].

А какво би станало, ако приложим алгоритъма и трети и четвърти и т.н. път? Разсъждения, аналогични на горните, ни водят до граничната *логаритмична сложност*. Въпреки значението на описаното обобщение (постигнахме логаритмична сложност!) ние няма да се спираме повече на него, тъй като съществува по-прост начин за постигане на такава сложност.

*Задачи за упражнение:*

1. Да се докаже, че най-добрата стъпка при квадратично търсене в нареден масив с n елемента е \sqrt{n}.

<details><summary>ДОКАЗАТЕЛСТВО 1.</summary>
<p>
	
- В най-лошия случай търсеният ключ е в последния интервал, което означава, че ще ни бъдат необходими [n/k] сравнения, за да определим нужния ни интервал, в който да приложим линейното търсене. Към тях следва да прибавим дължината на интервала, която при n кратно на k (в най-лошия случай, т.е. най-голям (пълен) интервал), е k-1. Получаваме, че в най-лошия случай при търсене със стъпка k се извършват не повече от [n/k] + k - 1 сравнения. Нека изследваме тази функция спрямо променливата k, която съхранява големината на стъпката. Искаме функцията да приема минимална стойност.
	
f(k) = [\frac{n}{k}] + k - 1, k \in{[1,n]}.
За да има локални екстремуми в този интервал, първата производна на функцията трябва да е равна на нула. Т.е.
f'(k) = \big([\frac{n}{k}] + k - 1\big)' = -1\time{}[n\times{}k^{-2}] + 1 = 0, т.е. [\frac{n}{k^2}] = 1 или максималното k, за което това е изпълнено е \max{k}=\sqrt{n}. A от това, че f''(k)=[2\time{}n\times{}k^{-3}] > 0 следва за k=\sqrt{n}, следва, че функцията която отброява сравненията в най-лошия случай, достига своя минимум.

</p>
</details>

2. Да се реализира двустепенно търсене със стъпки k и l. Да се намерят експериментално оптималните стойности на k и l като функции на n.

<details><summary>РЕШЕНИЕ 2.</summary>
<p>
	
След като доказахме, че първата стъпка k е най-добра при \sqrt{n}, то получения интервал, в който отново трябва да приложим квадратичното търсене ще е в най-лошия случай пълен и (*jуmp_сearch()*) ще е с дължина \sqrt{n}, откъдето следва че втората стъпка трябва да е с дължина \sqrt[4]{n}:

```cpp
#include <iostream>
#include <cmath>

using namespace std;

int a[] = {3, 4, 9, 12, 13, 14, 40, 44, 45, 50, 60, 60, 70, 80, 90, 100};
int n = sizeof(a) / sizeof(a[0]);

int cnt = 1;

int seq_search(int l, int r, int key) {
    while (l <= r) {
        if (a[l++] == key) {
            return l - 1;
        }
    }
    return -1;
}

int jump_search(int l, int r, int key, int step) {
    cnt++;
    int ind;
    for (ind = 0; ind < n && a[ind] < key; ind += step);
    if (cnt == 3) return seq_search(ind + 1 < step ? 0 : ind + 1 - step, n < ind ? n : ind, key);
        /* ако е извикано два пъти квадратичното търсене - продължи с последователно търсене със стъпка
        равна на корен квадратен от дължината на сектора в който търсим, т.е. корен квадратен от корен
        от n, което е корен 4-ти от дължината на цялата колекцията */
    else {
        return jump_search(ind + 1 < step ? 0 : ind + 1 - step, n < ind ? n :
                                                                ind, key, pow(n, 1.0 / (cnt + 1)));
    }
}

int main() {
    int el = jump_search(0, n - 1, 40,  pow(n, 1.0 / (cnt + 1)));
    (el != -1) ? cout << "element found at position: " << el : cout << "no such element";

    return 0;
}
```

</p>
</details>

### 3. Двоично търсене

В случай на множество с голям брой елементи и голям брой търсения е удобно използването на *двоино търсене* след предварително сортиране на елементите. Двоиното търсене е добър пример за приложение на римския принцип *разделяй и владей*. Основната идея е сложната задача да се разбие на няколко по-прости, те от своя страна също да се разделят на по-прости и т.н. Процесът продължава до достигане на достатъчно проста задача с тривиално решение.

Как стоят нещата при двоичното търсене? Предполагаме, че имаме сортиран масив. Идеята е масивът да се раздели на два подмасива и да се определи в кой от тях търсеният елемент със сигурност не би могъл да се намира. Въпросният подмасив се изключва от по-нататъшни разглеждания, а по-нататъшните усилия се насочват към по-перспективния. Би могло да се възрази, че двоичното търсене не представлява класически пример на приложение на стратегията *разделяй и владей*, тъй като тя предполага разглеждане и на *двата* подмасива. От горното изложение обаче се вижда, че тя не забранява ранно отрязване на безперспективните подмножества.

Как става разделянето? Нека означим търсения елемент с x и предположим, че масивът е сортиран. Да сравним x със средния елемент от масива (при четен брой елементи има два средни елемента и няма значение кой ще изберем). В случай на равенство търсенето приключва успешно. Ако x се окаже по-малък от средния елемент, веднага може да определим безперспективния подмасив. Действително, това са елементите вдясно от средата: тъй като масивът е сортиран, те всичките са по-големи от средния, а той пък от своя страна вече се е оказал по-голям от x. Аналогично се подхожда в случая, когато x се окаже по-голям от средния елемент, като тогава се отхвърля левия подмасив. След това същият процес се прилага към неотхвърления подмасив. На всяка стъпка разделяме перспективния масив на два подмасива с приблизително равен брой елементи. Процесът приключва успешно при намиране на търсения елемент или достигане до празния масив. Не е трудно да се види, че процесът винаги завършва. Действително, на всяка стъпка разглежданият масив намалява поне наполовина. *Поне*, тъй като винаги се отхвърля средният елемент на масива, а това при нечетен брой елементи означава, че се отхвърлят с един елемент повече отколкото остават. Впрочем това, че винаги се отхвърля поне един елемент, а именно средният, е съществено, тъй като някое от двете множества(лявото или дясното) може да се окаже празно. Въпреки това, и в този случай броят на елементите в разглеждания подмасив ще намалее строго (поне с 1).

Следвайки директно горните предписания, получаваме следната очевидна рекурсивна реализация на двоичното търсене (извиква се с *bin_search(ключ_който_търсим, 0, n-1)*):

```cpp
#include <iostream>
#include <algorithm>
#include <ctime>

using namespace std;

const int KEY = 10;
const int MAX = 10;

#define DataType char

struct Elem {
    int key;
    DataType data;
    /* ... */
} m[MAX];

int n;

bool way_to_sort(Elem i, Elem j) {
    return i.key < j.key;
}

void seq_insert(int key, DataType data) {
    m[n].key = key;
    m[n].data = data;
    n++;

    sort(m, m + n, way_to_sort);
}

int bin_search_rec(int key, int l, int r) {
    int mid;
    if (l > r) {
        return -1;
    }

    mid = (l + r) / 2;

    if (key < m[mid].key) {
        return bin_search_rec(key, l, mid - 1);
    } else if (key > m[mid].key) {
        return bin_search_rec(key, mid + 1, r);
    } else {
        return mid;
    }
}

void seq_display() {
    for (int i = 0; i < n; ++i) {
        cout << "position "
             << i
             << " : key "
             << m[i].key
             << " data "
             << m[i].data
             << endl;
    }
}

int main() {
    srand(time(nullptr));
    char ind;
    for (ind = 'a'; ind < 97 + MAX; ++ind) {
        seq_insert(rand() % (MAX * 2), ind);
    }

    cout << "the list contains the following items:" << endl;
    seq_display();

    int el = bin_search_rec(KEY, 0, MAX);

    (el != -1) ? cout << "Element with key: " << KEY << " is found at position " << el
                      << " with data " << m[el].data : cout << "No such element with key " << KEY << " in the array";

    return 0;
}
```
Описаният по-горе процес попринцип е рекурсиве. На практика обаче, на вяка стъпка се разглежда *точно едно* от двете подмножества. Вземайки предвид това, не е трудно да реализираме съответно итеративно решение:

```cpp
int bin_search_iter(int key) {
    int l = 0;
    int r = n - 1;
    int mid;

    while (l <= r) {
        mid = (l + r) / 2;
        if (key < m[mid].key) {
            r = mid - 1;
        } else if (key > m[mid].key) {
            l = mid + 1;
        } else {
            return mid;
        }
    }
    return -1;
}
```
Със съответната *main()* функция за тестване:

```cpp
int main() {
    srand(time(nullptr));
    char ind;
    for (ind = 'a'; ind < 97 + MAX; ++ind) {
        seq_insert(rand() % (MAX * 2), ind);
    }

    cout << "the list contains the following items:" << endl;
    seq_display();

    int el = bin_search_iter(KEY);

    (el != -1) ? cout << "Element with key: " << KEY << " is found at position " << el
                      << " with data " << m[el].data : cout << "No such element with key " << KEY << " in the array";

    return 0;
}
```

Горната функция използва два индекса l и r, указващи съответно лявата и дясната граница на разглежданата област. Разделянето на всяка стъпка става по средата *mid* на областта. Функцията връща позицията, на която се намира елементът с ключ *value* или -1, в случай на неуспех. Тъй като на всяка стъпка на алгоритъма разглежданият подмасив намалява поне наполовина, то горният алгоритъм извършва не повече от [log_2(n)+0.5]+1 сравнения. Това е горната граница както за успешно, така и за неуспешно търсене [*Уирт-1980*].

Да се опитаме да подобрим горния вариант на програмата. Очевидно основната идея на двоичното търсене „заковава“ горната граница на [log_2(n)+0.5]+1 сравнения. Въпреки това, място за подобрения има. Ще започнем с проста модификация на предложената програмна реализация и по-специално на начина на задаване на границите на разглежданата област. По-горе това ставаше с помощта на двойката индекси l и r, указващи съответно левия и десния ѝ край. Сега ще преминем към ново представяне, при което ще използваме offset = r-1 вместо r. Ще искаме още offset винаги да бъде степен на двойката. В случай, че размерът на първоначалната област е степен на двойката, това свойство очевидно ще се поддържа от само себе си без допълнителни усилия от наша страна. В противен случай ще се наложи да си го осигуряваме. Най-простия начин за справяне с проблема е на първата стъпка да разделим масива на две области, които непременно да имат размер, степен на двойката. Това не е трудно да се извърши, макар че ще доведе до пресичане на областите от първата стъпка. Така например, ако размерът на масива е 1000, едно добро решение е на първа стъпка да го разделим на следните области: **(1, 2,...,512)** и **(489, 490 ,..., 1000)**.

Двете области имат еднакъв размер, а именно 512, което е максималната степен на 2, ненадвишаваща размера на масива n = 1000. Елементите 489, 490,...,512 принадлежат и на двете области. За сметка на това обаче на всяка следваща стъпка размерът ще става тепен на двойката, при което общата ефективност на алгоритъма се очаква да се подобри. Тук тежката операция деление е заменена с поразредно изместване надясно, което води до допълнително подобрение. (Всъщност, това е малко спорно при днешните процесори.)

```cpp
unsigned get_max_pow_2(int k) {
    int pow_2;
    for (pow_2 = 1; pow_2 <= k; pow_2 <<= 1);
    return pow_2 >> 1;
}

int bin_search(int key) {
    int i, l, ind;
    i = get_max_pow_2(n);
    l = m[i].key >= key ? 0 : n - i + 1;
    while (i > 0) {
        i = i >> 1;
        ind = l + i;
        
        if (m[ind].key == key) {
            return ind;
        } else if (m[ind].key < key) {
            l = ind;
        }
    }
    return -1;
}
```
Бихме могли да се освободим от едното сравнение във вътрешността на цикъла. За сметка на това обаче вече няма да можем да прекратяваме преждевременно работата на алгоритъма при откриване на търсения елемент преди последната стъпка. Така промяната се оказва в известен смисъл спорна: 

```cpp
int bin_search(int key) {
    int i, l;
    i = get_max_pow_2(n);
    l = m[i].key >= key ? 0 : n - i + 1;
    
    while (i > 0) {
        i = i >> 1;
        if (m[l + i].key < key) {
            return l += i;
        }
    }
    
    return (l < MAX && m[++l].key == key ? l : -1);
}
```
Нека разгледаме по-внимателно идеята на алгоритъма. Не е трудно да забележим, че, който и от горните варианта да вземем, все едно за всяка стойност на размера n на областта, редът на последователните сравнения за всяка стъпка е предварително определен. Тогава бихме могли да ги разпишем изрично, премахвайки необходимостта от деление и от цикъл въобще. Получената програма се оказва изключително ефективна. Бентли съобщава за наблюдавано подобрение от около 4,5 пъти спрямо първоначалния класически вариант [*Bentley-1986*]. Разбира се, следва да се отбележи очевидното ограничение, че за разписването на цикъла в последователни условни конструкции, е необходимо размерът на областта да бъде поне приблизително известен. Освен това външният вид на програмата е способен да убие всеки ентусиазъм:

```cpp
int bin_search(int key) {
    int l = 0;
    if (m[16].key < key) {
        l = 20 - 16 + 1;
    }
    if (m[l + 8].key < key) {
        l += 8;
    }
    if (m[l + 4].key < key) {
        l += 4;
    }
    if (m[l + 2].key < key) {
        l += 2;
    }
    if (m[l + 1].key < key) {
        l += 1;
    }
    return (l < 20 && m[++l].key == key ? l : -1);
}
```

Макар двоичното търсене да е изключително ефективно, то следва да се използва предпазливо. Основният му недостатък е, че непременно изисква пряк достъп до елементите на множеството, което ни ограничава до използването на масив и не ползволява никакви динамични структури. Изискването за наредба на елементите на множеството пък от своя страна създава още по-големи проблеми пред вмъкването. Действително, ако вмъкваме новите елементи в края на масива, ще трябва да го сортираме преди всяко търсене, следващо вмъкване, което очевидно е крайно неразумно. Налага се вмъкване, при което масивът да остане сортиран. Тази операция е много неефективна, особено при по-малка стойност на ключа на вмъквания n + 1-ви елемент, тъй като това води до изместване на всички по-големи от него елементи с една позиция надясно. Това изисква изместване средно n/2, а в най-лошия случай - на n елемента (n е броя на елементите *преди* вмъкването).

По-горе считахме изрично, че множеството не допуска повтаряне на ключове. Не е трудно обаче да се забележи, че дори и да допуснем повтаряне, двоичното търсене отново ще работи. Действително, то отново не намира точно един елемент, в случай че такъв изобщо съществува. Сега остава да се съобрази, че масивът е сортиран. Тогава останалите елементи с този ключ следва да се намират в едната или в двете посоки, непосредствено до намерения елемент. Същата идея може да се използва за решаване на по-общата задача за намиране на всички елементи, попадащи в даден интервал.

Проблеми, свързани с необходимостта от преместване на голям брой елементи, възникват и при изтриването. Всъщност, при изтриването на малък брой елементи, е разумно те просто да се *маркират* като изтрити, без преместване. При търсене те следва да се прескачат по подходящ начин. Най-добре е ключовете им все пак да се използват при търсенето, и, едва в случай на успешно завършване, да се проверява дали намереният елемент не е изтрит. След това да се извършва евентуално търсене сред съседните му елементи в двете посоки.

### 3. Фибоначиево търсене

Макар на пръв поглед да изглежда странно, понякога бихме могли да постигнем по-висока скорост на търсене, ако се откажем от разделянето на две *равни* части. По-долу ще разгледаме две модификации на двоичното търсене, всяка от които се основава на специфично съображение. Действително, основен недостатък на двоичното търсене е тежката операция деление, извършвана на всяка стъпка от изпълнението на алгоритъма. За съжаление, делението на две е тежка операция и може да забави алгоритъма. Ето защо е препоръчително при разработването на практически приложения, редът

mid = \frac{(l+r)}{2}

да се замени с 

mid = (l+r)>>1

Предложената модификация съществено използва вътрешното представяне на числата двоична бройна система и факта, че делението на 2 може да се замени с отхвърляне на последната цифра на делимото, т.е. с изместване на една позиция на дясно. Практически почти всички съвременни процесори разполагат с такава машинна инструкция. Ще припомним, че за произволна бройна система с основа p е в сила: Частното при целочислено деление на p с частно и остатък може да се намери чрез отхвърляне на последната цифра на делимото (остатъка от делението).

Макар и много малко вероятно, може да се окаже, че използваната от Вас машина не разполага с подходяща инструкция за изместване надясно с един бит (почти невъзможно). В такъв случай е удачно да се използва така нареченото Фибоначиево търсене. Ще припомним, че числата на Фибоначи се задават с рекурентна дормула:

F_0 = 0, F_1 = 1, F_n = F_{n-1} + F_{n-2}, n > 2

Фибоначиевото търсене силно напомня двоичното – масивът се разделя на две части, като едната се изключва от по-нататъшни разглеждания. Единствената разлика е начинът на избор на елемента, с който ще сравняваме. Нека предположим, че търсеното става в n-елементен масив, като n = F_k - 1. На първата стъпка сравняваме търсения ключ x с m[F_{k-1}].key. В случай на равенство търсенето приключва успешно. В случай че x < m[F_{k-1}].key на следващата стъпка разглеждаме елементите 1, 2, 3, ..., F_{k-1} - 1. Ако пък x > m[F_{k-1}].key на следващата стъпка остават за разглеждане елементите F_{k-1} + 1, F_{k - 1} + 2, ..., n = F_k. Директно се пресмята, че в първия случай за следващата стъпка получаваме последователност с дължина F_{k - 1} - 1, а във втория – F_{k - 2} - 1. Процесът се повтаря върху неотхвърлената част до намиране на търсения елемент или достигане до празната последователност (*Horowitz-1977*). Една възможна реализация на Фибоначиевото търсене изглежда така (l > 0 и е такова, че F_k + l = n + 1 и F_{k+1} > n+1):

```cpp
int fib[MAX]; /* Числата на Фибоначи, ненадвишаващи n */

int find_fib(int n) {
    fib[0] = 0;
    fib[1] = 1;

    for (int k = 2;; k++) {
        if ((fib[k] = fib[k - 1] + fib[k - 2]) > n) {
            return k - 1;
        }
    }
}

int fib_search(int key) {
    int p, q, r, k;

    k = find_fib(n);
    p = fib[k - 1];
    q = fib[k - 2];
    r = fib[k - 3];

    if (key > m[p].key) {
        p += n - fib[k] + 1;
    }
    while (p > 0) {
        if (key == m[p].key) {
            return p;
        } else {
            if (key < m[p].key) {
                if (0 == r) {
                    p = 0;
                } else {
                    int t;
                    p -= r;
                    t = q;
                    q = r;
                    r = t - r;
                }
            } else {
                if (1 == q) {
                    p = 0;
                } else {
                    p += r;
                    q -= r;
                    r -= q;
                }
            }
        }
    }
    
    return -1;
}
```
Каква е ефективността на Фибоначиевото търсене? Оказва се, че ползата от премахването на делението не е голяма. Подобно на двоичното търсене, редът на извършване на сравненията е предварително определен за всяка стойност на n. На практика Фибоначиевото търсене строй дърво. Лесно се забелязва, че разликата във височините на поддърветата за всеки връх е най-много 1, т.е. дървото е *балансирано*. Този тип дървета са известни в литературата като *дървета на Фибоначи* (те са най-лошия случай на балансирани дървета, защото са по-високи от съответното идеално балансирано дърво с 45%). Така, в най-лошия случай Фибоначиевото търсене изследва дърво, с 45% по-високо от това на двоичното търсене, поради което се оказва по-неефективно от него.

### 4. Интерполационно търсене

Когато човек търси „Бонев“ в телефонния указател, той гледа в началото на указателя, а когато търси „Янева“ – в края. Не бихме ли могли по подобен начин да оптимизираме двоичното търсене?

Нека го разгледаме по-внимателно. При двоичното търсене избрахме средния елемент mid по формулата mid = \frac{l+r}{2}">. Да го запишем по друг начин:

mid = 1 + \frac{r - l}{2}   (*)

Получената формула показва, че следващата позиция на разделяне на интервала се получава, като към началото му добавим половинта на дължината му. В случая на телефонния указател, човек не работи по тази формула. Вместо в средата той търси съответно в началото или в края на указателя. Това може да се изрази чрез формула от типа на (*), като за целта 1/2 се замени с друго подходящо число. Как да изберем това число? Нека се върнем отново към телефонния указател. Там човек се опитва да определи приблизителната позиция на търсеното име, изхождайки от първата му буква, знаейки първата и последната букви от азбуката. По аналогичен начин бихме могли да опитаме да намерим приблизителната позиция на произволен елемент X, знаейки стойността X, както и стойностите на началото и края на разглеждания интервал. Ясно е, че тази относителна позиция може да се зададе с интерполационната формула:

mid = l + k * (r - l), където k = \frac{x - m[l].key}{m[r].key - m[l].key}

Коефициентът k, който замества константата 1/2 всъщност ни дава приблизителната позиция на търсения елемент в разглеждания интервал. При реализацията на интерполационното търсене следва да се отчетат някои специфични особености, свързани с пресмятането на стойността на k. На първо място, следва да се предпазим от деление на 0, в случай, че стойностите на всички ключове от разглеждания интервал [l, r] съвпадат. На второ място, следва да гарантираме, че k\in{[0, 1]}. Действително, в противен случай стойността на mid би излязла извън границите на разглеждания интервал [l,r]. Когато k излезе извън границите [0,1] спокойно можем да считаме, че търсеният елемент липсва.

Каква е ефективността на разгледаното подобрение? В случай на равномерно разпределение интерполационното търсене дава наистина забележителни резултати! Тогава горното приближение, зададено от k, се оказва много близо до истинската позиция на търсения елемент и той бива открит значително по-бързо в сравнение с двоичното търсене. Доказва се, че тогава интерполационното търсене извършва по-малко от log_2{(log_2(n)))} + 1 сравнения както при успешно, така и при неуспешно търсене. За да може да оценим по видимо ефективността на изложения метод, ще посочим, че функцията log_2{(log_2(n))} расте изключително бавно. Например log_2{(log_2{1000000000})}<5

```cpp
int interpol_search(int key) {
    int r, l, mid;
    float k;

    l = 0;
    r = n - 1;
    while (l <= r) {
        if (m[r].key == m[l].key) {
            if (m[l].key == key) {
                return l;
            } else {
                return -1;
            }
        }

        k = (float) (key - m[l].key) / (m[r].key - m[l].key);
        if (k < 0 || k > 1) {
            return -1;
        }

        mid = (int) (l + k * (r - l) + 0.5);

        if (key < m[mid].key) {
            r = mid - 1;
        } else if (key > m[mid].key) {
            l = mid + 1;
        } else {
            return mid;
        }
    }

    return -1;
}
```
Въпреки безспорните предимства на интерполационното търсене, то следва да се използва изключително внимателно. На първо място не трябва да се забравя, че то е подобрение (много добро) на двоичното търсене, поради което наследява основните и най-неприятните му недостатъци, свързани с изискването за пряк достъп и наредба на елементите на множеството. На второ място, следва да се отбележат допълнителните изисквания и недостатъци, които се налагат (всяко нещо си има цена!). От една страна се изисква ключовете да бъдат числа или да могат лесно да се интерпретират като такива, така че k да попада винаги в интервала [0,1]. В противен случай методът може да се окаже неприложим. На трето място, следва да се обърне специално внимание на факта, че тук се работи с числа с плаваща запетая и се използва тежката аритметична операция деление. За съжаление, тук не можем да се отървем от делението така лесно, както при двоичното търсене: от една страна делението вече не е на степен 2, а от друга – не е целочислено.

Изключително съществено се оказва и изискването ключовете на елементите да са равномерно разпределени. В случай, че това не е така, то скоростта му може да падне чувствително под тази на двоичното търсене, приближавайки се до линейна. Не е трудно да се конструира такъв пример. Нека за целта се опитаме да търсим числото 2 в следното множество:

1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 10000

Освен това при малки стойности на n числата log_2(n) и log_2{log_2(n)} не се различават съществено, поради което обикновено се счита, че използването на интерполационното търсене не си струва риска. От друга страна, при особено големи файлове, при големи ключове или при външно разположение на данните, когато сравненията са особено скъпи, следва твърдо да се предпочита интерполационното търсене.

Източници:

[1] П. Добринков, П. Наков, Програмиране = ++Алгоритми;